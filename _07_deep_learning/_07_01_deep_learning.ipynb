{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Introducción a las redes neuronales\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción\n",
    "\n",
    "## 1.1. IA, Machine learning y Deep learning\n",
    "\n",
    "La Inteligencia Artificial (AI) es un campo de investigación muy antiguo. Comenzó en la década de 1950; en ese momento, los pioneros de la IA estaban convencidos de que podían hacer pensar a las máquinas. El enfoque inicial era intentar modelar tareas cognitivas y programar esas tareas en computadoras. Es decir, al principio, la IA se trataba de personas programando en una máquina, aquellas actividades que querían ser resueltas por una máquina. Por lo que, aunque el término se refiere a \"inteligencia\", estos programas no eran \"inteligentes\", sino simplemente un conjunto sofisticado de ordenes y reglas.\n",
    "\n",
    "Este enfoque ya se encuentra obsoleto. Ahora sabemos que algunas tareas son tan complejas, que nunca podremos prediseñar un sistema para tener un buen desempeño en éstas.\n",
    "\n",
    "El enfoque moderno para resolver este tipo de problemas implica el uso de datos. Esto es a lo que se refiere el término *learning* dentro del *Deep Learning* (y *Machine Learning*), **aprender de los datos**. Entonces, con esta breve introducción, podemos decir que la Inteligencia Artificial es un concepto amplio que incluye *Machine Learning*, y que incluye *Deep Learning*. La AI no significa necesariamente aprender de los datos, pero el aprendizaje automático sí, y el *Deep Learning* no es más que *Machine Learning*, pero con redes neuronales.\n",
    "\n",
    "El cambio de paradigma se podría resumir en que antiguamente, se intentaban modelizar datos y reglas para obtener respuestas; mientras que en la actualidad, se modelizan datos y respuestas (*labeled data*), para obtener las reglas y que éstas permitan extrapolar nuevas respuestas.\n",
    "\n",
    "<center><img src=\"../_images\\nn_ai_ml_dl.png\" alt=\"Drawing\" style=\"width: 275px;\"/></center>\n",
    "\n",
    "## 1.2. Neuronas y redes neuronales\n",
    "\n",
    "**Neuronas:**\n",
    "\n",
    "Una neurona es la unidad básica de procesamiento que podemos encontrar dentro de una red neuronal. Similar a una neurona biológica, éstas, reciben estimulos externos denominados valores de entrada con los que realizar cálculos y generar un valor de salida. Dicho de otro modo, una neurona no es más que una función $f(x)$.\n",
    "\n",
    "Esta función no es más que una suma ponderada de los valores de entrada, y que incopora además un término independiente denominado *bias* (similiar a la regresión lineal). Esta función se puede expresar como un sumatorio del producto de las entradas por sus ponderaciones, como un producto vectorial:\n",
    "\n",
    "- Una matriz es un tensor de 2D\n",
    "- Transformación afín, $\\vec{y} = W\\cdot\\vec{x} + \\vec{b}$, donde $W$ es el tensor de las ponderaciones, $\\vec{x}$ son los datos de entrada, $\\vec{y}$ los de salida, y $\\vec{b}$ es el denominado *bias*.\n",
    "- $W$ y $\\vec{b}$ son parámetros del modelo que deben ser encontrados mediante el entrenamiento.\n",
    "\n",
    "<center><img src=\"../_images\\nn_neuron.png\" alt=\"Drawing\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "**Redes neuronales:**\n",
    "\n",
    "Una red neuronal, no es más que un conjunto de neuronas conectadas entre sí en forma de capas, cada capa contiene un número finito de neuronas. Una capa se puede representar mediante un tensor que aplica una transformación afín (transformación lineal seguida de una traslación), así, en cada una de las capas.\n",
    "\n",
    "<center><img src=\"../_images\\nn_layers.png\" alt=\"Drawing\" style=\"width: 450px;\"/></center>\n",
    "\n",
    "Neuronas en la misma capa, reciben la misma información de entrada, relativa a los datos de salida de la capa anterior. Existen tres categorizaciones de capas en función de su posición dentro de la red neuronal:\n",
    "\n",
    "- Capa de entrada\n",
    "- Capas ocultas\n",
    "- Capa de salida\n",
    "\n",
    "Una de las pocas restricciones que existe a la hora de crear una red neuronal, es que las neuronas de una misma capa, no pueden tener relación o interconectarse entre sí.\n",
    "\n",
    "<center><img src=\"../_images\\nn_nn.png\" alt=\"Drawing\" style=\"width: 350px;\"/></center>\n",
    "\n",
    "Las capas permiten obtener conocimiento jerarquizado, es decir, que las neuronas de las primeras capas obtengan un conocimiento más simple, y que las neuronas de las siguientes capas y a partir de los datos de salida de capas anteriores, desarrollen un conocimiento más complejo. El nombre de *deep learning* proviene de la utilización de muchas capas de neuronas.\n",
    "\n",
    "Cuando se utiliza una red neuronal, en verdad lo que se está haciendo es concatenar neuronas, y por lo tanto transformaciones lineales. El problema es que está demostrado matemáticamente, que cuando se suman muchas de éstas, la transformación de los datos de origen se correspondería con aplicarles únicamente una única transformación lineal.\n",
    "\n",
    "$$f_1(x) = 2 + 2x$$\n",
    "$$f_2(x) = 1 + 4x$$\n",
    "$$f_t(x) = 3 + 6x$$\n",
    "\n",
    "Esto hace que toda una estructura de neuronas concatenadas, colapse hasta reducir todo el sistema a una única neurona, y por lo tanto una única transformación afín. Para evitar este suceso, se introduce el término: función de activación. Estas funciones distorsionan los valores de salida añadiendo deformaciones no lineales. Algunas de estas funciones pueden ser:\n",
    "\n",
    "- Sigmoide\n",
    "- Tangente hiperbólica (TanH)\n",
    "- ReLU (rectified linear unit, ReLU for friends)\n",
    "\n",
    "<center><img src=\"../_images\\nn_activation_function.png\" alt=\"Drawing\" style=\"width: 350px;\"/></center>\n",
    "\n",
    "Al añadir estas funciones no lineales, se resuelve el problema de la concatenación de múltiples neuronas.\n",
    "\n",
    "$$\\vec{y} = f\\left(W\\cdot\\vec{x} + \\vec{b}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entrenamiento de redes neuronales\n",
    "\n",
    "Los parámetros de la red se asignan inicialmente de forma aleatoria. Luego, después de cada paso de la red, es decir, después de cada *epoch*, las predicciones de la red se comparan con los valores reales, aplicando una función de pérdida. Esta puntuación se utiliza para actualizar los parámetros de la red, con un proceso llamado *backpropagation*.\n",
    "\n",
    "- *Backpropagation* es un proceso complejo que implica calcular el gradiente de los parámetros de la red.\n",
    "\n",
    "El proceso de entrenamiento es solo un proceso de optimización, que normalmente se realiza mediante un algoritmo basado en el descenso de gradiente. Los valores de los gradientes se calculan utilizando el algoritmo de *backpropagation*. Cada *epoch* hará que la puntuación de pérdidas sea menor y que las predicciones sean mejores.\n",
    "\n",
    "En la práctica, tenemos que ajustar el número de *epochs* (y otros parámetros), hasta obtener un resultado que sea lo suficientemente bueno para nuestro propósito. De hecho, si el número de *epochs* es demasiado alto, nuestro modelo puede sobreajustarse a los datos de entrenamiento. En ese caso, su rendimiento será peor cuando el modelo esté expuesto a datos que no ha visto anteriormente.\n",
    "\n",
    "- El ajuste fino del número de *epochs* y otros parámetros (por ejemplo, el número y la forma de las capas) se conoce como optimización de hiperparámetros o ajuste de hiperparámetros.\n",
    "- Los parámetros del modelo son los valores $W$ y $b$ de cada capa, y éstos se determinan mediante el entrenamiento.\n",
    "\n",
    "## 2.1. Ajuste de hiperparámetros\n",
    "\n",
    "En resumen, cuando estamos tratando de obtener un modelo de aprendizaje profundo, el proceso que seguiremos es:\n",
    "\n",
    "- Decidir sobre la arquitectura de la red (número de capas, tipo de cada capa, tamaño de cada capa)\n",
    "- Decidir las funciones de activación en cada capa\n",
    "- Decidir los parámetros relacionados con el proceso de optimización (por ejemplo, tasa de aprendizaje)\n",
    "- Decidir la función de pérdida que usaremos\n",
    "- Decidir las métricas que usaremos para evaluar el desempeño del modelo\n",
    "- Decidir los parámetros de entrenamiento (número de épocas, tamaño del lote)\n",
    "- Decida cómo dividir los datos entre conjuntos de entrenamiento, validación y prueba.\n",
    "\n",
    "Obtenemos retroalimentación de esas decisiones con los resultados de la formación aplicada al conjunto de validación. Entrenamos una vez, cambiamos algunos de los hiperparámetros, entrenamos de nuevo, decidimos si eso es mejor y seguimos hasta encontrar un modelo que sea lo suficientemente satisfactorio para nuestros propósitos.\n",
    "\n",
    "Después de eso, finalmente evaluamos el modelo en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X. Bibliografía\n",
    "\n",
    "- Canal de YouTube Dot CSV. Miniserie: ¿Qué son las redes neuronales?. https://www.youtube.com/watch?v=MRIv2IwFTPg&list=PL-Ogd76BhmcB9OjPucsnc2-piEE96jJDQ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
